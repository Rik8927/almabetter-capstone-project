{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "7wuGOrhz0itI",
        "578E2V7j08f6",
        "67NQN5KX2AMe",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "nqoHp30x9hH9",
        "yiiVWRdJDDil",
        "T5CmagL3EC8N",
        "Z-hykwinpx6N",
        "EyNgTHvd2WFk",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rik8927/almabetter-capstone-project/blob/main/AIRLINE_PASSENGER_REFFEREL_PREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -AIRLINE PASSENGER REFFEREL PREDICTION\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -**Arghya Roy\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data includes airline reviews from 2006 to 2019 for popular airlines around the world withmultiple choice and free text questions. Data is scraped in Spring 2019. The main objectiveis to predict whether passengers will refer the airline to their friends.\n",
        "**airline: Name of the airline.\n",
        "\n",
        "overall: Overall point is given to the trip between 1 to 10.\n",
        "\n",
        "author: Author of the trip\n",
        "\n",
        "review date: Date of the Review\n",
        "\n",
        "customer review:Review of the customers in free text format\n",
        "\n",
        "aircraft: Type of the aircraft\n",
        "\n",
        "traveller type: Type of traveler (e.g. business, leisure)\n",
        "\n",
        "cabin: Cabin at the flight date flown: Flight date\n",
        "\n",
        "seat comfort: Rated between 1-5\n",
        "\n",
        "cabin service: Rated between 1-5\n",
        "\n",
        "foodbev: Rated between 1-5\n",
        "\n",
        "entertainment: Rated between 1-5\n",
        "\n",
        "ground service: Rated between 1-5\n",
        "\n",
        "value for money: Rated between 1-5\n",
        "\n",
        "recommended: Binary, target variable."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so the objective is to predict whether passengers will refer the airline to their friends."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import lightgbm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Importing all models from sklearn to be used in our model building\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "import time\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# Importing  metrics for evaluation for our models\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import accuracy_score,precision_score\n",
        "from sklearn.metrics import recall_score,f1_score,roc_curve, roc_auc_score"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "#importing the dataset from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#load the dataset from drive\n",
        "airline_df = pd.read_excel('/content/data_airline_reviews (1).xlsx')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "#Top five rows of data\n",
        "airline_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Last five rows of data\n",
        "airline_df.tail()"
      ],
      "metadata": {
        "id": "qW1UeKAclwE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "#Total number of rows and columns\n",
        "airline_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Column of the dataset\n",
        "airline_df.columns"
      ],
      "metadata": {
        "id": "Ev47MX8ymBMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "#Information\n",
        "airline_df.info()\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "airline_df.recommended.unique()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "airline_df.nunique()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "#counting the number of duplicate values\n",
        "airline_df.duplicated().sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the null value in each column\n",
        "airline_df.isnull().sum()"
      ],
      "metadata": {
        "id": "j0T3fDIxnFyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#overall description of the data by using transpose\n",
        "airline_df.describe().T"
      ],
      "metadata": {
        "id": "OQvzLd2InIbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so from the above we can clearly understand that,overall count is-59401,seat_comfort-56211,cabin_service-56240,food_bev=48341,entertrainment-40230,ground_service-37169 and value_for_money-59237."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "airline_df.columns\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "#overall description of the data by using transpose\n",
        "airline_df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so from the above we can clearly understand that,overall count is-59401,seat_comfort-56211,cabin_service-56240,food_bev=48341,entertrainment-40230,ground_service-37169 and value_for_money-59237.\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "#check the unique value\n",
        "airline_df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#Eliminate the null values\n",
        "airline_df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#Which traveller type has more ratings?\n",
        "#setting the figure size and plotting the graph\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x=airline_df ['traveller_type'])"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?\n"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find which traveller type has more ratings given so they can give future refferences."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, solo leisure type has got top ratings and business class has less ratings."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the above graph we can easily detect thta, in which segent we can emphasize ,so we can take for refferel in future."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#setting the figure size and plotting the grap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=airline_df['traveller_type'],y=airline_df['value_for_money'])"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From th above graph we can know which traveller type  give us most rating value for value of money."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above graph it is clear that which type of traveller give us more ratings for value of money and whom give us less.as we can see from the above the solo leisure give more ratings."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the above graph we can conclude that in which field we have to emphasize and in which field we are good."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#what is the average rating of Food_bev and entertrainment given by passenger\n",
        "#performing the group by method\n",
        "eda_4=airline_df.groupby('cabin')[['food_bev','entertainment']].mean().reset_index()\n",
        "print(eda_4)"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize']=(10,7)\n",
        "eda_4.plot(x='cabin',y=[\"food_bev\",\"entertainment\"],kind=\"bar\")\n"
      ],
      "metadata": {
        "id": "JQfmgylc6Ea3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out the ratings of the average rating of Food_bev and entertrainment given by passenger."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Economy class has lowest rating regarding food_bev and entertainment."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so we can easily find out on which sector we are poor in performance."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#Which cabin type has more service ratings?\n",
        "#cabin type and cabin service ratings\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(x=airline_df.cabin, y=airline_df.cabin_service, hue = airline_df['recommended'], palette= ['orange','purple'])"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out which cabin type has more ratings."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.First class traveller are least likely to recommend the airlines. 2.Recommendation is most probable when tn service is given full star rating i.e 5 out of 5 rating. 3.In economy class if we get rating between 4 to 5 that mean it will recommend.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "wecan easily find out which cabin type has more ratings and where we have to emphasize."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#Which traveller type has overall service ratings?\n",
        "#Traveller type and overall service ratings (out of 10 )\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.scatterplot(x=airline_df.traveller_type, y=airline_df.overall, hue = airline_df['recommended'], palette= ['indigo','orange'])\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use scatterplot graph to find out the overall servuce ratings out of 10."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so buisness class gives the poor ratings and will not recommend."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have to emphasize on the service of business class."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "#Traveller type and value for money ratings (out of 5 )\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=airline_df.traveller_type, y=airline_df.value_for_money, hue = airline_df['recommended'], palette= ['blue','orange'])"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use this barplot graph to find out the traveller type and valur for money ratings."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above graph it is clear that,the family leisure give more ratings and the business class give less ratings."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can know from the above graph,that in which field we are backdrawing."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Get the number of trips each airline make.\n",
        "trip_by_airlines = airline_df['airline'].value_counts()\n",
        "trip_by_airlines\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 10 airlines with most speed\n",
        "plt.figure(figsize=(20,5))\n",
        "trip_by_airlines[:10].plot(kind='bar',color='purple')\n",
        "plt.xlabel('Airline Type',fontsize=12)\n",
        "plt.ylabel('Top 10 Airline',fontsize=15)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EEMBUXBwHplD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out which plane has more round."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above graph it is clear that-\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Turkish Airlines\n",
        "\n",
        "1.  Spirit Airlines\n",
        "2.  American Airlines\n",
        "3. United Airlines\n",
        "4. Bristish Airways\n",
        "5.Emirates\n",
        "6.China south Airlines\n",
        "7.Frontier Airlines\n",
        "8.Ryanair\n",
        "9.Delta Airlines\n",
        "10.\n"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above ggraph we can find out that which airline has more round,so we can give more maintenance to that."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "#Frequency distribution using histogram\n",
        "airline_df.hist(bins=30,figsize=(20,15),color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out all other ratings."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, from the above plot we can conclude that: 1.Overall:1 is the highest rating and 10 is the second best rating. 2.Seat Comfort:Rating 1 is highest and rationg 4 is the second highest. 3.Cabin service:5 is the highest rating and 1 is th second highest rating. 4.Food Beverage: 1 is the highest rating and 4 is the second highest rating. 5.Entertrainment: 1 is the highest rating and 4 is the second highest rating. 6.Ground Service: 1 is the highest rating and 5 is the second highest rating 7.Value for money: 1 is the highest rating and 5 is the second highest rating.\n",
        "\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out in which sector we have to emphasize."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the fig size and plotting the graph\n",
        "label_for_overall_rating = ['1.0','10.0','9.0','8.0','2.0','7.0','3.0','5.0','6.0','4.0']\n",
        "data7 = airline_df['overall'].value_counts().values\n",
        "print(airline_df['overall'].value_counts())\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.axis(\"equal\")\n",
        "plt.title('overall rating',bbox={'facecolor':'0.8', 'pad':5})\n",
        "plt.pie(data7, labels = label_for_overall_rating,radius=1.9,autopct='%0.2f%%',shadow=True,textprops={'fontsize': 14})\n",
        "plt.legend(loc='center',shadow=True,fancybox=True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out customer overall satisfiction."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 42% passengers gave an overall rating below 3.0 . So it,suggests that people are not very much satisfied with airline services.There are still need of improvements"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customer are not satisfied,so we have to improve the services."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "label_for_money = ['1.0','5.0','4.0','2.0','3.0']\n",
        "data6 = airline_df['value_for_money'].value_counts().values\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.axis(\"equal\")\n",
        "plt.title('value_for_money',bbox={'facecolor':'0.8', 'pad':5})\n",
        "plt.pie(data6, labels = label_for_money,radius=1.6,autopct='%0.2f%%',shadow=True,textprops={'fontsize': 14})\n",
        "plt.legend(loc='center',shadow=True,fancybox=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pie chart alaways give better understandiung in percentage."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "36% people are not satisfied with value_for_money service.As they give 1.0 rating.40% people are giving 4.0 and 5.0 rating for value_for_money.So overall rating is avg.So we can say that avg value for money service may be negatively impact airline business."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can easily understand from the above where we should excel in performance."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "label_for_ent_service = ['1.0','4.0','5.0','3.0','2.0']\n",
        "data5 = airline_df['entertainment'].value_counts().values\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.axis(\"equal\")\n",
        "plt.title('Entertainment rating',bbox={'facecolor':'0.8', 'pad':5})\n",
        "plt.pie(data5, labels = label_for_ent_service,radius=1.6,autopct='%0.2f%%',shadow=True,textprops={'fontsize': 14})\n",
        "plt.legend(loc='center',shadow=True,fancybox=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out customer satisfiction about seat."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "38% people are giving 4.0 and 5.0 rating for seat comfort.So overall rating is bad.So we can say that bad value for entertainment service negatively impact airline business."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we findout overall ratings is bad,we need to improve."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "label_for_seat_service = ['1.0','4.0','3.0','5.0','2.0']\n",
        "data4 = airline_df['seat_comfort'].value_counts().values\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.axis(\"equal\")\n",
        "plt.title('Seat Comfort rating',bbox={'facecolor':'0.8', 'pad':5})\n",
        "plt.pie(data4, labels = label_for_seat_service,radius=1.6,autopct='%0.2f%%',shadow=True,textprops={'fontsize': 14})\n",
        "plt.legend(loc='center',shadow=True,fancybox=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out percentage of seat comfort."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "42% people are giving 4.0 and 5.0 rating for seat comfort.So overall rating is good.So we can say that good value for seat comfort service positively impact airline business."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The overal ratings is good,bt still we can improve in this field."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "\n",
        "#Traveller type and value for money ratings (out of 5 )\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(x=airline_df.traveller_type,y= airline_df.value_for_money, hue = airline_df['recommended'], palette= ['purple','yellow'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out relation beween traveller type and value for money."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the overall ratings is avrage from all segment."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to improve on this field."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(airline_df.corr(),annot=True)"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to find out the relation between the parameters-\n",
        "1 indicates a perfect positive correlation\n",
        "(-1) indicates a perfect negative correlation\n",
        "0 indicates no correlation"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so,value_for_money is highly corelate with the overall."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "# pairplot with hue sex\n",
        "seaborn.pairplot(airline_df)\n",
        "# to show\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view the overall we use this pairplot."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "so from the above pairplot,iw can get a clear view of in which sector what rating we get."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0):\n",
        "\n",
        "H0: There is no significant association between passenger type and referral behavior.\n",
        "In both cases, the null hypothesis suggests that there is no relationship or association between the two categorical variables.\n",
        "\n",
        "Alternative Hypothesis (Ha):\n",
        "Ha: There is a significant association between passenger type and referral behavior.\n",
        "The alternative hypothesis suggests that there is a significant relationship or association between the two categorical variable. chi-square test for independence to analyze the data and determine whether the p-value obtained from the test is less than the chosen significance level (e.g., α = 0.05). If the p-value is less than α, we can reject the null hypothesis, indicating that there is a significant association between passenger type and referral behavior. If the p-value is greater than α, we would fail to reject the null hypothesis, suggesting no significant association."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "contingency_table = pd.crosstab(airline_df['traveller_type'], airline_df['recommended'])\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "print(f\"Chi-Square Test Statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "5s2faMYqY5P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if p < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant relationship between Passenger_Type and Referral_Status.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant relationship between Passenger_Type and Referral_Status.\")"
      ],
      "metadata": {
        "id": "J2tX7c9-zD_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "chi-square test."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test helps to determine whether there is a statistically significant association or relationship between two categorical variables—in this case,traveller_type and recommended. This can help you understand if passenger type influences the likelihood of making referrals."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0):\n",
        "\n",
        "H0: There is no significant association between passenger type and referral behavior. In both cases, the null hypothesis suggests that there is no relationship or association between the two categorical variables.\n",
        "\n",
        "Alternative Hypothesis (Ha): Ha: There is a significant association between passenger type and referral behavior. The alternative hypothesis suggests that there is a significant relationship or association between the two categorical variable. chi-square test for independence to analyze the data and determine whether the p-value obtained from the test is less than the chosen significance level (e.g., α = 0.05). If the p-value is less than α, we can reject the null hypothesis, indicating that there is a significant association between passenger type and referral behavior. If the p-value is greater than α, we would fail to reject the null hypothesis, suggesting no significant association."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "contingency_table = pd.crosstab(airline_df['overall'], airline_df['value_for_money'])\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table, lambda_=\"log-likelihood\")\n"
      ],
      "metadata": {
        "id": "Gg9g8P8-M_uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.05\n",
        "\n",
        "if p < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant association between overall  and value_for_money.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant association between overall and value_for_money.\")\n"
      ],
      "metadata": {
        "id": "brlQmEoD9moP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "G-test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of airline passenger referral prediction, we may want to use the G-test to determine if there is a statistically significant association between the referral overall and the value_for_money. If the relation between overall and value_for_money is suitable then the customer satisfiction is good.so,we can set our marketing strategy according to that.\n"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0):\n",
        "\n",
        "Null Hypothesis: The coefficient (β) for a specific predictor variable in the logistic regression model is equal to zero.\n",
        "Symbolically: H0: β = 0\n",
        "Interpretation: This null hypothesis assumes that the predictor has no effect on the log-odds of the binary outcome variable. In other words, the predictor is not associated with the outcome.\n",
        "Alternative Hypothesis (Ha):\n",
        "\n",
        "Alternative Hypothesis: The coefficient (β) for a specific predictor variable in the logistic regression model is not equal to zero.\n",
        "Symbolically: Ha: β ≠ 0\n",
        "Interpretation: The alternative hypothesis suggests that the predictor has a statistically significant effect on the log-odds of the binary outcome variable. In other words, the predictor is associated with the outcome."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import statsmodels.api as sm\n",
        "df_cleaned = airline_df.dropna()\n",
        "df_cleaned['overall'] = df_cleaned['overall'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "df_cleaned['value_for_money'] = df_cleaned['value_for_money'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "X = df_cleaned[['overall', 'value_for_money']]\n",
        "X = pd.get_dummies(X, columns=['overall'], drop_first=True)  # Dummy encode passenger type\n",
        "y = df_cleaned['value_for_money']\n",
        "X = sm.add_constant(X)  # Add a constant (intercept) term\n",
        "model = sm.Logit(y, X)\n",
        "results = model.fit()\n",
        "print(results.summary())\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if p < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant relationship between overall and value for money.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant relationship between overall and value for money.\")"
      ],
      "metadata": {
        "id": "dmGfRKoXGQe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression provides easily interpretable results. You can interpret the coefficients of predictor variables as the log-odds of the outcome, allowing you to understand how each predictor influences the likelihood of a referral. This interpretability can be valuable for making business decisions."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "#Dropping Unnecessary Collumn\n",
        "#Checking percentage wise missing values\n",
        "def missing_values_per_check(df):\n",
        "  percent_missing=airline_df.isnull().sum() * 100/len(airline_df)\n",
        "  missing_values_df=pd.DataFrame({'column_name':airline_df.columns,\n",
        "                                  'percent_missing':percent_missing})\n",
        "  return missing_values_df.sort_values('percent_missing',ascending=False)\n",
        "  #Check percentage wise missing values\n",
        "missing_values_per_check(airline_df)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Showing the unique aircraft name\n",
        "airline_df.aircraft.unique()"
      ],
      "metadata": {
        "id": "DU1Of1SY41CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of unique aircrafts\n",
        "airline_df.aircraft.nunique()"
      ],
      "metadata": {
        "id": "-wzzmNhe4-J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df=airline_df.drop(['aircraft'],axis=1)"
      ],
      "metadata": {
        "id": "iWG0P9ow5DU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the column from data which are not for Use\n",
        "airline_df = airline_df.drop(['author','review_date','route','date_flown','customer_review'],axis=1)\n",
        "airline_df.head()"
      ],
      "metadata": {
        "id": "1ySNJ4QF5Jva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reason for dropping columns: Author - Being the categorical with high Variability not required for prediction. Route - Not needed for building a model as it is independent of the Services and Quality of travel. Date_flown - Not needed for building a model as it is not a time series data, also some common time period is there between 2 dates. Review_date - Similar to Date_flown Customer_review - As it is related to overall review feature of the datasets. On the basis of null value percentage we divide our data in two parts-\n",
        "\n",
        "high_null = columns which have high percentage of null values. low_null = columns which have low percentage of null values."
      ],
      "metadata": {
        "id": "JMAuQsUm5biy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the Numeric column\n",
        "low_null = ['overall','seat_comfort','cabin_service','value_for_money']\n",
        "high_null = ['food_bev','entertainment','ground_service']"
      ],
      "metadata": {
        "id": "yubfeKm75lCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "#Imputation technique using Quantile-1 value\n",
        "def impute_by_q1_values(df,column):\n",
        "  Q1=np.percentile(np.sort(df[column].dropna()),25)\n",
        "  df[column].fillna(Q1,inplace=True)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Looping the null value column\n",
        "for col in low_null:\n",
        "  impute_by_q1_values(airline_df,col)"
      ],
      "metadata": {
        "id": "3PvuGa2N8Vo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputaion technique using median imputation\n",
        "def median_imputation(df,column):\n",
        "  df[column].fillna(df[column].median(),inplace=True)"
      ],
      "metadata": {
        "id": "suVSk_Mv8l27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coping the null value column\n",
        "for col in high_null:\n",
        "  median_imputation(airline_df,col)"
      ],
      "metadata": {
        "id": "ize9Nrha81GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After imputed null values\n",
        "airline_df.head(1)"
      ],
      "metadata": {
        "id": "wtt1N-lH9A6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove recommended null value row\n",
        "airline_df.dropna(subset=['recommended'],inplace=True)\n"
      ],
      "metadata": {
        "id": "aEpbzsFh9Pw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGbDxtD_gWyY"
      },
      "outputs": [],
      "source": [
        "airline_df['traveller_type'].fillna(method='ffill',inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_BfiQuWgxpV"
      },
      "outputs": [],
      "source": [
        "airline_df['traveller_type'].fillna(method='ffill',inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwsW3WAfg2Yo"
      },
      "outputs": [],
      "source": [
        "airline_df['traveller_type'].fillna(method='ffill',inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61i94Yy7q2ac"
      },
      "outputs": [],
      "source": [
        "airline_df['cabin'].fillna(airline_df['cabin'].mode().values[0],inplace=True)\n",
        "airline_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the new null value percentage\n",
        "missing_values_per_check(airline_df)"
      ],
      "metadata": {
        "id": "W0LcLkni9x99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df.shape"
      ],
      "metadata": {
        "id": "UcWorP6kAew6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is better to clean the data and work on it."
      ],
      "metadata": {
        "id": "4qKibOC6AlB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "#Converting target column\n",
        "airline_df['recommended'].replace({'yes':1,'no':0},inplace=True)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df.head(2)"
      ],
      "metadata": {
        "id": "EyEJsNxNCGPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(airline_df.corr(),annot=True)"
      ],
      "metadata": {
        "id": "5HhZEq7bCJWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "correlation plot Drop overall column as it has highest correlation value than others."
      ],
      "metadata": {
        "id": "Lqu5OwdnCZtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "#Creating a function to remove multicollinear\n",
        "def calc_vif(X):\n",
        "\n",
        "   # Calculating VIF\n",
        "   vif = pd.DataFrame()\n",
        "   vif[\"variables\"] = X.columns\n",
        "   vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "   return(vif)"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(airline_df[[i for i in airline_df.describe().columns if i not in ['recommended','value_for_money','overall']]])"
      ],
      "metadata": {
        "id": "XELDndNCDeIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop overall column\n",
        "airline_df.drop([\"overall\"], axis=1, inplace=True)\n",
        "airline_df.drop([\"airline\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "y8U9bNciDm_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "#Defining the dependent and independent variables\n",
        "#Seperating the dependent and the independent column\n",
        "y=airline_df['recommended']\n",
        "x=airline_df.drop(columns='recommended')\n",
        "x.columns"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "x=pd.get_dummies(x)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "BuU_Z-gI5_7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.head(2)"
      ],
      "metadata": {
        "id": "-0oLD6lw6GHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The percentage of no.labels  of target varibale is\",np.round(y.value_counts()[0]/len(y)*100))\n",
        "print(\"The percentage of no.labels of target variable is\", np.round(y.value_counts()[1]/len(y)*100))"
      ],
      "metadata": {
        "id": "GzUt_6Fy6NL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The percentage of both labels('yes','no') is approximately equal.So no need of Handling Class Imbalance Technique."
      ],
      "metadata": {
        "id": "jXstAJrM6Rh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "#Train and Test Split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of x_train and x_test data\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "Gf8CbE5V6jZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of y_train and y_test data\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "5QUodvBV6prV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "log_reg=LogisticRegression(fit_intercept=True,max_iter=10000)\n",
        "log_reg.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "#Logistic regression fitting\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg.coef_"
      ],
      "metadata": {
        "id": "51UQMlVSdvZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg.intercept_"
      ],
      "metadata": {
        "id": "BSyRvo_gr3c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg.score(x_test,y_test)"
      ],
      "metadata": {
        "id": "43XXyju6eC7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=log_reg.predict(x_test)"
      ],
      "metadata": {
        "id": "BykwxgpDeNMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "93 percent accuracy with logistic regression"
      ],
      "metadata": {
        "id": "JL37KqHWeVMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Report of logistic regresiion\n",
        "report_IR=classification_report(y_test,y_pred)\n",
        "print(report_IR)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression is often used in airline passenger referral prediction and similar classification tasks for several reasons:\n",
        "\n",
        "**Simplicity and Interpretability**: Logistic regression is a simple and interpretable algorithm. It provides straightforward coefficients for each feature, which can be easily understood and explained to stakeholders. In industries like the airline industry, interpretability is often crucial for making business decisions.\n",
        "\n",
        "**Binary Classification**: Referral prediction is typically a binary classification problem, where the goal is to predict whether a passenger will refer others or not. Logistic regression is well-suited for binary classification tasks because it models the probability of one of the two possible outcomes.\n",
        "\n",
        "**Linearity**: Logistic regression assumes a linear relationship between the features and the log-odds of the target variable, making it appropriate when there is a reasonably linear separation between the classes or when the relationship can be adequately approximated as linear.\n",
        "\n",
        "**Efficiency**: Logistic regression is computationally efficient and can handle large datasets with a relatively small computational cost. This efficiency is valuable in industries like airlines, which deal with a large volume of passenger data.\n",
        "\n",
        "**Low Overfitting Risk**: Logistic regression is less prone to overfitting, especially when the number of features is small or when regularization techniques like L1 or L2 regularization are applied.\n",
        "\n",
        "**Probabilistic Output**: Logistic regression provides a probabilistic output, which can be useful in decision-making. Airlines can set different referral thresholds based on the predicted probabilities to customize their marketing or incentive strategies.\n",
        "\n",
        "**Feature Importance**: Logistic regression can help identify the most influential features for the prediction, allowing airlines to focus on the factors that most affect passenger referral behavior.\n",
        "\n",
        "**Quick Prototyping**: Logistic regression is a quick and simple algorithm to implement, making it suitable for rapid prototyping and initial model development.\n",
        "\n",
        "It's important to note that while logistic regression has its advantages, it may not always be the best choice for every situation. In cases where the relationship between features and the target variable is highly nonlinear or where there are complex interactions between features, more advanced machine learning techniques such as decision trees, random forests, gradient boosting, or neural networks may be considered. The choice of algorithm should depend on the specific characteristics of the data and the problem at hand.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bQp6cck83GIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "#Confusion matrix of logistic regression\n",
        "confuse_matrix_lr=confusion_matrix(y_test,y_pred)\n",
        "#Ploting confusion matrix\n",
        "sns.heatmap(confuse_matrix_lr,annot=True,fmt=\".1f\")\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic=LogisticRegression()\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores=cross_val_score(log_reg,x_train,y_train,cv=10)\n",
        "print('Cross-validation Accuracy Scores',scores)"
      ],
      "metadata": {
        "id": "XheMQu7Heqeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores=pd.Series(scores)\n",
        "scores.min(),scores.mean(),scores.max()"
      ],
      "metadata": {
        "id": "CZVruMLChApw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to return all Models Accuracy Score\n",
        "\n",
        "def accuracy_of_each_model(model,X_train,X_test):\n",
        "\n",
        "  #predicting a train datas\n",
        "  y_train_preds=model.predict(X_train)\n",
        "\n",
        "  #predicting a test datas\n",
        "  y_test_preds=model.predict(X_test)\n",
        "\n",
        "  #storing all training scores\n",
        "  train_scores=[]\n",
        "\n",
        "  #storing all test scores\n",
        "  test_scores=[]\n",
        "  metrics=['Accuracy_Score','Precsion_Score','Recall_Score','Roc_Auc_Score']\n",
        "\n",
        "  # Get the accuracy scores\n",
        "  train_accuracy_score = accuracy_score(y_train,y_train_preds)\n",
        "  test_accuracy_score = accuracy_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_accuracy_score)\n",
        "  test_scores.append(test_accuracy_score)\n",
        "\n",
        "  # Get the precision scores\n",
        "  train_precision_score = precision_score(y_train,y_train_preds)\n",
        "  test_precision_score = precision_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_precision_score)\n",
        "  test_scores.append(test_precision_score)\n",
        "\n",
        "  # Get the recall scores\n",
        "  train_recall_score =recall_score(y_train,y_train_preds)\n",
        "  test_recall_score =recall_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_recall_score)\n",
        "  test_scores.append(test_recall_score)\n",
        "\n",
        "  # Get the roc_auc scores\n",
        "  train_roc_auc_score=roc_auc_score(y_train,y_train_preds)\n",
        "  test_roc_auc_score =roc_auc_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_roc_auc_score)\n",
        "  test_scores.append(test_roc_auc_score)\n",
        "\n",
        "  return train_scores,test_scores,metrics"
      ],
      "metadata": {
        "id": "k-I42cHTxIee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models=[log_reg]\n",
        "name=['Logistic Regression Model']"
      ],
      "metadata": {
        "id": "Pwgk8XgvxLfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_ in range(len(models)):\n",
        "  train_score_,test_score_,metrics_=accuracy_of_each_model(models[model_],x_train,x_test)\n",
        "  print(\"-*-*-\"*3+f\"{name[model_]}\"+\"-*-*-\"*4)\n",
        "  print(\"\")\n",
        "  print(pd.DataFrame(data={'Metrics':metrics_,'Train_Score':train_score_,'Test_Score':test_score_}))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "iN2-Cg0IxphM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-validation is used to estimate how well the model with a specific set of hyperparameters generalizes to unseen data. The most common form of cross-validation is k-fold cross-validation, where the data is divided into k subsets (folds), and the model is trained and evaluated k times, each time using a different fold as the validation set and the rest as the training set.Based on the performance metrics obtained from cross-validation, you can then make adjustments to the hyperparameters. You might repeat this process with different hyperparameter values or using techniques like grid search, random search, or Bayesian optimization to systematically explore the hyperparameter space."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Initializing decission tree model object\n",
        "tree_classify=DecisionTreeClassifier()\n",
        "#Training a model with x and y\n",
        "tree_classify.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training accuracy of decission tree model is\",tree_classify.score(x_train,y_train))\n",
        "print(\"Testing accuracy of decision tree model is\",tree_classify.score(x_test,y_test))"
      ],
      "metadata": {
        "id": "duIePMSX6CHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=tree_classify.predict(x_test)\n",
        "#Report of decision tree\n",
        "report_dec_tree=classification_report(y_test,y_pred)\n",
        "print(report_dec_tree)\n"
      ],
      "metadata": {
        "id": "BGzApCC_6GMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here our model is overfitted.so Hyperparameter need to done make a decission tree model."
      ],
      "metadata": {
        "id": "6rZw8dXm6OCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "#Setting the parameter and scoring matrix\n",
        "parameters = {\"criterion\":[\"gini\",\"entropy\"],\"max_depth\":[5,7],\"min_samples_split\":[5,7],\"min_samples_leaf\":[2,3]}\n",
        "scoring_=['f1','recall','precision','accuracy']\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing hyperparameter tuning using gridsearchcv\n",
        "\n",
        "#Setting an estimator and crossvalidation\n",
        "tree_cv=GridSearchCV(estimator=tree_classify, param_grid=parameters, scoring=scoring_, cv=5, refit='accuracy')\n",
        "\n",
        "#Fitting x and y to gridsearchcv model using an estimator Decission tree classifier\n",
        "tree_cv.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "RfnYz3036mNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling on best params\n",
        "tree_cv.best_params_"
      ],
      "metadata": {
        "id": "Xw-R3NLF6rnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling on best score\n",
        "tree_cv.best_score_"
      ],
      "metadata": {
        "id": "FtxYM4kj6uYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "93% accuracy of decission tree by hyperparamter tuning."
      ],
      "metadata": {
        "id": "-EUNRhE16yOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to return all Models Accuracy Score\n",
        "\n",
        "def accuracy_of_each_model(model,X_train,X_test):\n",
        "\n",
        "  #predicting a train datas\n",
        "  y_train_preds=model.predict(X_train)\n",
        "\n",
        "  #predicting a test datas\n",
        "  y_test_preds=model.predict(X_test)\n",
        "\n",
        "  #storing all training scores\n",
        "  train_scores=[]\n",
        "\n",
        "  #storing all test scores\n",
        "  test_scores=[]\n",
        "  metrics=['Accuracy_Score','Precsion_Score','Recall_Score','Roc_Auc_Score']\n",
        "\n",
        "  # Get the accuracy scores\n",
        "  train_accuracy_score = accuracy_score(y_train,y_train_preds)\n",
        "  test_accuracy_score = accuracy_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_accuracy_score)\n",
        "  test_scores.append(test_accuracy_score)\n",
        "\n",
        "  # Get the precision scores\n",
        "  train_precision_score = precision_score(y_train,y_train_preds)\n",
        "  test_precision_score = precision_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_precision_score)\n",
        "  test_scores.append(test_precision_score)\n",
        "\n",
        "  # Get the recall scores\n",
        "  train_recall_score =recall_score(y_train,y_train_preds)\n",
        "  test_recall_score =recall_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_recall_score)\n",
        "  test_scores.append(test_recall_score)\n",
        "\n",
        "  # Get the roc_auc scores\n",
        "  train_roc_auc_score=roc_auc_score(y_train,y_train_preds)\n",
        "  test_roc_auc_score =roc_auc_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_roc_auc_score)\n",
        "  test_scores.append(test_roc_auc_score)\n",
        "\n",
        "  return train_scores,test_scores,metrics"
      ],
      "metadata": {
        "id": "Ra_oTe4fP16Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models=[tree_cv]\n",
        "name=['Decision Tree Model After Hyperparameter Tuning']"
      ],
      "metadata": {
        "id": "abonC2XOP943"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_ in range(len(models)):\n",
        "  train_score_,test_score_,metrics_=accuracy_of_each_model(models[model_],x_train,x_test)\n",
        "  print(\"-*-*-\"*3+f\"{name[model_]}\"+\"-*-*-\"*4)\n",
        "  print(\"\")\n",
        "  print(pd.DataFrame(data={'Metrics':metrics_,'Train_Score':train_score_,'Test_Score':test_score_}))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "MgRqqS_KQKBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  GridSearchCV is used in this case.\n",
        "  Hyperparameter Tuning: GridSearchCV is primarily used for hyperparameter tuning. In machine learning models like decision trees, random forests, or support vector machines, there are hyperparameters that need to be set before training the model. For example, in decision trees, you might need to specify the maximum depth, minimum samples per leaf, etc. Finding the best combination of these hyperparameters can significantly impact model performance.\n",
        "\n",
        "Systematic Search: GridSearchCV performs a systematic search over a predefined grid of hyperparameter values. It tests all possible combinations of hyperparameters within the specified grid. This ensures that you don't miss the best hyperparameter values by manually guessing or trying a few combinations.\n",
        "\n",
        "Cross-Validation: GridSearchCV combines grid search with cross-validation. It divides the dataset into multiple folds and trains and evaluates the model on different subsets of the data. This helps in obtaining a more robust estimate of the model's performance for each hyperparameter combination and reduces the risk of overfitting to the specific training set.\n",
        "\n",
        "Efficiency: While GridSearchCV exhaustively searches the hyperparameter space, it does so in a structured and efficient way. It doesn't require manual intervention for trying out different combinations, making the hyperparameter tuning process less error-prone and time-consuming.\n",
        "\n",
        "Selection of Best Hyperparameters: Once GridSearchCV completes its search, it identifies the combination of hyperparameters that yielded the best performance according to a specified evaluation metric (e.g., accuracy, F1-score). This allows you to choose the best-performing model for your specific prediction task."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "random_forest=RandomForestClassifier()\n",
        "random_forest.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest.score(x_test,y_test)"
      ],
      "metadata": {
        "id": "bW5qMZWfDDhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Report of decission tree\n",
        "report_ran_forest=classification_report(y_test,y_pred)\n",
        "print(report_ran_forest)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to return all Models Accuracy Score\n",
        "\n",
        "def accuracy_of_each_model(model,X_train,X_test):\n",
        "\n",
        "  #predicting a train datas\n",
        "  y_train_preds=model.predict(X_train)\n",
        "\n",
        "  #predicting a test datas\n",
        "  y_test_preds=model.predict(X_test)\n",
        "\n",
        "  #storing all training scores\n",
        "  train_scores=[]\n",
        "\n",
        "  #storing all test scores\n",
        "  test_scores=[]\n",
        "  metrics=['Accuracy_Score','Precsion_Score','Recall_Score','Roc_Auc_Score']\n",
        "\n",
        "  # Get the accuracy scores\n",
        "  train_accuracy_score = accuracy_score(y_train,y_train_preds)\n",
        "  test_accuracy_score = accuracy_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_accuracy_score)\n",
        "  test_scores.append(test_accuracy_score)\n",
        "\n",
        "  # Get the precision scores\n",
        "  train_precision_score = precision_score(y_train,y_train_preds)\n",
        "  test_precision_score = precision_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_precision_score)\n",
        "  test_scores.append(test_precision_score)\n",
        "\n",
        "  # Get the recall scores\n",
        "  train_recall_score =recall_score(y_train,y_train_preds)\n",
        "  test_recall_score =recall_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_recall_score)\n",
        "  test_scores.append(test_recall_score)\n",
        "\n",
        "  # Get the roc_auc scores\n",
        "  train_roc_auc_score=roc_auc_score(y_train,y_train_preds)\n",
        "  test_roc_auc_score =roc_auc_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_roc_auc_score)\n",
        "  test_scores.append(test_roc_auc_score)\n",
        "\n",
        "  return train_scores,test_scores,metrics"
      ],
      "metadata": {
        "id": "lTfcrC-yDzMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models=[random_forest]\n",
        "name=['Random Forest Model After Hyperparameter Tuning']"
      ],
      "metadata": {
        "id": "EbsWGGXyEFy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_ in range(len(models)):\n",
        "  train_score_,test_score_,metrics_=accuracy_of_each_model(models[model_],x_train,x_test)\n",
        "  print(\"-*-*-\"*3+f\"{name[model_]}\"+\"-*-*-\"*4)\n",
        "  print(\"\")\n",
        "  print(pd.DataFrame(data={'Metrics':metrics_,'Train_Score':train_score_,'Test_Score':test_score_}))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "91hNmsS-ERlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "random_forest_gridcv=GridSearchCV(estimator=random_forest,param_grid=parameters,cv=5,verbose=2)\n",
        "# Fit the Algorithm\n",
        "random_forest_gridcv.fit(x_train,y_train)\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_gridcv.best_params_"
      ],
      "metadata": {
        "id": "FOix_brCKQVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Random Forest classifier is used in airline passenger referral prediction  for several reasons:\n",
        "\n",
        "**Ensemble Learning:** Random Forest is an ensemble learning technique that combines the predictions of multiple decision trees. This ensemble approach tends to provide more accurate and robust results compared to using a single decision tree. It helps reduce overfitting and captures complex relationships in the data.\n",
        "\n",
        "**Robustness to Noise**: Airline passenger referral prediction datasets can be noisy, with various factors influencing referral behavior. Random Forest can handle noisy data effectively by averaging predictions from multiple trees, which can smooth out noise and reduce the impact of outliers.\n",
        "\n",
        "**Feature Importance**: Random Forest can measure the importance of each feature in making predictions. This is valuable in understanding which factors influence passenger referral behavior the most. Airlines can use this information to tailor marketing strategies and incentives.\n",
        "\n",
        "**Handling Categorical Data**: Random Forest can handle both numerical and categorical features, making it suitable for datasets that include passenger characteristics, travel history, and other categorical attributes.\n",
        "\n",
        "**Non-linearity**: Random Forest is capable of capturing non-linear relationships between features and the target variable. This is essential because passenger referral behavior is often influenced by a combination of factors that may not follow a linear pattern.\n",
        "\n",
        "**Model Interpretability**: While Random Forest is an ensemble of trees, it can still provide insights into feature importance and decision paths within individual trees. This can aid in explaining the model's predictions to stakeholders and understanding why certain passengers are more likely to refer others.\n",
        "\n",
        "**Scalability**: Random Forest can handle datasets with a large number of features and a substantial amount of data, which is common in the airline industry where passenger datasets can be extensive.\n",
        "\n",
        "**Out-of-Bag Validation**: Random Forest uses an out-of-bag (OOB) validation technique to estimate the model's performance without the need for a separate validation dataset. This simplifies the model evaluation process.\n",
        "\n",
        "**Flexibility and Customization**: Random Forest allows for parameter tuning and customization, such as controlling the number of trees in the ensemble, the maximum depth of the trees, or the minimum samples required for a split. This flexibility enables fine-tuning to optimize model performance.\n",
        "\n",
        "**Reliable Performance**: Random Forest tends to provide reliable performance across various types of data and is less sensitive to data preprocessing choices compared to some other machine learning algorithms"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the knowledge of the business and the problem usecase. The Classification metrics of Recall is given first priority , Accuray is given second priority , and ROC AUC is given third priority.\n",
        "In the context of airline passenger referral prediction, the reasons why recall might be given first priority in this scenario:\n",
        "\n",
        "Safety and Security: The primary concern for airlines is the safety and security of passengers. Identifying potential security threats or passengers who may pose risks is of utmost importance. Recall, in this context, represents the ability of the model to correctly identify as many potential referrals or security-related cases as possible. High recall means that fewer potential security threats are missed.\n",
        "\n",
        "Minimizing False Negatives: False negatives in this context would be cases where the model fails to identify a passenger who should be referred for further screening or investigation. A high recall ensures that a minimal number of such cases are missed, reducing the risk of overlooking security concerns.\n",
        "\n",
        "Regulatory Compliance: Airlines are often subject to strict regulations and security standards enforced by aviation authorities. These regulations may require airlines to have robust passenger referral systems to identify and report suspicious activities or passengers. High recall can help ensure compliance with these regulations.\n",
        "\n",
        "Risk Mitigation: Airlines want to minimize the risk associated with passenger screening and referrals. High recall helps in identifying passengers who may need further scrutiny, reducing the chance of allowing potentially risky individuals to board flights.\n",
        "\n",
        "Customer Experience: While security is paramount, airlines also want to provide a positive passenger experience. By minimizing false positives (cases where passengers are referred unnecessarily), airlines can reduce inconvenience and delays for passengers who do not pose any security threats. High recall can help strike a balance between security and passenger convenience.\n",
        "\n",
        "Prioritizing Referrals: Recall can be particularly important when resources for further screening are limited. By focusing on passengers with a higher likelihood of being security concerns, airlines can allocate resources more effectively.\n",
        "\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we should use decission tree classifier.\n",
        "Decision tree classifiers can be used for classification tasks, including airline passenger referral prediction, for several reasons:\n",
        "\n",
        "Interpretability: Decision trees are highly interpretable models. The rules learned by a decision tree can be visualized, which makes it easier to understand how the model is making decisions. This interpretability can be crucial in cases where you need to explain the reasoning behind predictions, such as in airline passenger referral prediction, where transparency might be required for regulatory or customer service purposes.\n",
        "\n",
        "Handling Both Numeric and Categorical Data: Decision trees can handle both numeric and categorical features, which is often the case with real-world datasets like passenger information, which may include a mix of data types.\n",
        "\n",
        "Non-Linear Relationships: Decision trees are capable of capturing non-linear relationships between features and the target variable. This flexibility can be beneficial when the relationship between passenger attributes and the likelihood of referral is complex and not easily modeled with linear methods.\n",
        "\n",
        "Automatic Feature Selection: Decision trees can perform automatic feature selection by giving higher importance to features that are more relevant to the classification task. This can help simplify the model by excluding irrelevant or redundant features.\n",
        "\n",
        "Ensemble Methods: Decision trees can be used as building blocks for more advanced ensemble methods like Random Forests and Gradient Boosting. These ensemble methods can often improve predictive accuracy while retaining some level of interpretability."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "#Model 4:K-Nearest Neighbour\n",
        "k_neighbour=KNeighborsClassifier()\n",
        "k_neighbour.fit(x_train,y_train)\n",
        "y_pred=k_neighbour.predict(x_test)"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute accuracy on the training set\n",
        "train_accuracy=k_neighbour.score(x_train,y_train)\n",
        "print(train_accuracy)\n",
        "#Compute accuracy on the test set\n",
        "test_accuracy=k_neighbour.score(x_test,y_test)\n",
        "print(test_accuracy)"
      ],
      "metadata": {
        "id": "_qMf2RlQFtzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coonfuse_matrix_k_neighbour=confusion_matrix(y_test,y_pred)\n",
        "coonfuse_matrix_k_neighbour"
      ],
      "metadata": {
        "id": "9q4X1--4Fwt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#area under ROC curve\n",
        "roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "dlDAxPoEF0eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(k_neighbour,'regression_model.joblib')"
      ],
      "metadata": {
        "id": "5WRqprnzGAZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 5: Suport Vector Machine\n",
        "support_vector = SVC(kernel='linear')\n",
        "support_vector.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "yGHIuauAHbPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#score for support vector machine\n",
        "support_vector.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "p4IbQzqHHfc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "support_vector_con_mat = confusion_matrix( y_test,y_pred)\n",
        "support_vector_con_mat"
      ],
      "metadata": {
        "id": "d7eJYf0AHrV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 6:Naive base Clasifier\n",
        "#Implementing naive bayes model\n",
        "naive_bayes=GaussianNB()\n",
        "naive_bayes.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "ZqPyE4oTHwL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes.score(x_train,y_train)"
      ],
      "metadata": {
        "id": "n2yqzd4CH290"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making prediction on the testing net\n",
        "y_pred=naive_bayes.predict(x_test)\n",
        "#Comparing actual response values(y_test) with predicted response valuyes(y_pred)\n",
        "from sklearn import metrics\n",
        "print(\"Gaussian naive bayes model accuracy(in %):\",metrics.accuracy_score(y_test,y_pred)*100)"
      ],
      "metadata": {
        "id": "l_4PriFoH5_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fg6nh9CpIQE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGIwPSIw3VRl"
      },
      "outputs": [],
      "source": [
        "#Creating a function to return all Models Accuracy Score\n",
        "\n",
        "def accuracy_of_each_model(model,X_train,X_test):\n",
        "\n",
        "  #predicting a train datas\n",
        "  y_train_preds=model.predict(X_train)\n",
        "\n",
        "  #predicting a test datas\n",
        "  y_test_preds=model.predict(X_test)\n",
        "\n",
        "  #storing all training scores\n",
        "  train_scores=[]\n",
        "\n",
        "  #storing all test scores\n",
        "  test_scores=[]\n",
        "  metrics=['Accuracy_Score','Precsion_Score','Recall_Score','Roc_Auc_Score']\n",
        "\n",
        "  # Get the accuracy scores\n",
        "  train_accuracy_score = accuracy_score(y_train,y_train_preds)\n",
        "  test_accuracy_score = accuracy_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_accuracy_score)\n",
        "  test_scores.append(test_accuracy_score)\n",
        "\n",
        "  # Get the precision scores\n",
        "  train_precision_score = precision_score(y_train,y_train_preds)\n",
        "  test_precision_score = precision_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_precision_score)\n",
        "  test_scores.append(test_precision_score)\n",
        "\n",
        "  # Get the recall scores\n",
        "  train_recall_score =recall_score(y_train,y_train_preds)\n",
        "  test_recall_score =recall_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_recall_score)\n",
        "  test_scores.append(test_recall_score)\n",
        "\n",
        "  # Get the roc_auc scores\n",
        "  train_roc_auc_score=roc_auc_score(y_train,y_train_preds)\n",
        "  test_roc_auc_score =roc_auc_score(y_test,y_test_preds)\n",
        "\n",
        "  train_scores.append(train_roc_auc_score)\n",
        "  test_scores.append(test_roc_auc_score)\n",
        "\n",
        "  return train_scores,test_scores,metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models=[k_neighbour,support_vector,naive_bayes]\n",
        "name=['k_neighbour','support vector','naive bayes']"
      ],
      "metadata": {
        "id": "8T6xBw7_IUck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_ in range(len(models)):\n",
        "  train_score_,test_score_,metrics_=accuracy_of_each_model(models[model_],x_train,x_test)\n",
        "  print(\"-*-*-\"*3+f\"{name[model_]}\"+\"-*-*-\"*4)\n",
        "  print(\"\")\n",
        "  print(pd.DataFrame(data={'Metrics':metrics_,'Train_Score':train_score_,'Test_Score':test_score_}))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "NwRoayvyIX8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Models used for this Classsification problem are\n",
        "\n",
        "1.Logistic Regression Model 2.Decision Tree Model 3.Random Forest Model 4.K-Nearest Neighbor Model 5.Support Vector Machine Model 6.Naive Bayes\n",
        "\n",
        "We performed Hyperparameter tuning using Gridsearch CV method for Decision Tree Model, Random Forest Model , K-Nearest Neighbor ,Support Vector Machine and Naive Bayes. To increase accuracy and avoid Overfitting Criteria, this is done. After that, we finalized the Gradient Boosting model by fine-tuning the hyperparameters.\n",
        "\n",
        "Based on the knowledge of the business and the problem usecase. The Classification metrics of Recall is given first priority , Accuray is given second priority , and ROC AUC is given third priority.\n",
        "\n",
        "We have built classifier models using 6 different types of classifiers and all these are able to give accuracy of more than 90%.* We can conclude that LogisticRegression gives the best model.\n",
        "\n",
        "model evaluation metrics comparison, we can see that Support Vector Machine being the model with highest accuracy rate by a very small margin, works best among the experimented models for the given dataset.\n",
        "\n",
        "The most important feature are overall rating and Value for money that contribute to a model's prediction whether a passenger will recommened a particular airline to his/her friends.\n",
        "\n",
        "The classifier models developed can be used to predict passenger referral as it will give airlines ability to identify impactful passengers who can help in bringing more revenues.\n",
        "\n",
        "As a result, in order to increase their business or grow, our client must provide excellent cabin service, ground service, food beverage entertainment, and seat comfort."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}